import streamlit as st
from groq import Groq


# --- 1. CONFIGURACI√ìN DE LA P√ÅGINA (Desaf√≠o 6) ---
st.set_page_config(
    page_title="Cerbero IA", # T√≠tulo de la pesta√±a
    page_icon="ü§ñ"
)


# T√≠tulo principal de la aplicaci√≥n (Desaf√≠o 6)
# --- 2. CONFIGURACI√ìN DE GROQ ---
# ‚ö†Ô∏è INGRESA TU API KEY AQU√ç ‚ö†Ô∏è
# Obt√©n tu clave de: https://console.groq.com/keys
# TU CLAVE API YA EST√Å PEGADA
GROQ_API_KEY = "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"


# Lista de modelos disponibles de Groq
MODELOS_DISPONIBLES = [
    'llama-3.1-8b-instant',
    'llama-3.3-70b-versatile',
    'deepseek-r1-distill-llama-70b'
]


# Inicializa el cliente de Groq. Manejamos errores si la clave no est√°.
try:
    client = Groq(api_key=GROQ_API_KEY)
except Exception as e:
    st.error("Error: La clave API de Groq es inv√°lida o falta.")
    st.info("Por favor, obt√©n tu clave de https://console.groq.com/keys y p√©gala en la l√≠nea 22 del archivo app.py.")
    st.stop() # Detiene la ejecuci√≥n si la clave falla


# --- 3. SELECCI√ìN DEL MODELO (Nuevo) ---
# Se agrega un men√∫ desplegable en la barra lateral para seleccionar el modelo
with st.sidebar:
    st.header("Configuraci√≥n de IA")
    MODELO_SELECCIONADO = st.selectbox(
        "Selecciona el Motor de IA (Groq)",
        MODELOS_DISPONIBLES,
        index=0, # Por defecto selecciona el primer modelo
        key="modelo_seleccionado"
    )
    st.info(f"Modelo actual: **{MODELO_SELECCIONADO}**")


# --- 4. INICIALIZACI√ìN DE LA SESI√ìN DE CHAT ---


# Define avatares para el chat
AVATARS = {"user": "üë§", "assistant": "ü§ñ"}


# Inicializa el historial de chat en st.session_state si no existe
if "messages" not in st.session_state:
    st.session_state.messages = []
    
    # Mensaje inicial del asistente usando el nuevo avatar
    st.session_state.messages.append({"role": "assistant", "content": "¬°Hola! Soy un asistente impulsado por IA. Puedes cambiar mi motor en el men√∫ de la izquierda."})


# --- 5. VISUALIZACI√ìN DEL HISTORIAL DENTRO DE UN RECUADRO ---


# El contenedor permite que el historial de chat aparezca en un recuadro con scroll.
# Se a√±ade una 'key' para asegurar el redibujado.
with st.container(height=500, border=True, key="chat_history_container"): 
    # Muestra el historial de mensajes al recargar la aplicaci√≥n
    for message in st.session_state.messages:
        # Usamos el diccionario AVATARS para asignar el emoji correcto
        with st.chat_message(message["role"], avatar=AVATARS[message["role"]]):
            st.markdown(message["content"])


# --- 6. MANEJO DE LA ENTRADA DEL USUARIO ---


# Captura la entrada del usuario en el campo de chat
if prompt := st.chat_input("Escribe tu mensaje aqu√≠..."):
    # 1. Muestra el mensaje del usuario en la interfaz
    st.session_state.messages.append({"role": "user", "content": prompt})
    # Usamos el avatar del usuario
    with st.chat_message("user", avatar=AVATARS["user"]):
        st.markdown(prompt)


    # 2. Genera la respuesta de la IA (con streaming)
    # Usamos el avatar del asistente
    with st.chat_message("assistant", avatar=AVATARS["assistant"]):
        
        # Creamos un placeholder para actualizar el texto en vivo
        message_placeholder = st.empty() 
        
        # Prepara los mensajes para la API de Groq
        messages_for_api = [
            {"role": "system", "content": f"Eres un asistente de chat impulsado por el modelo {MODELO_SELECCIONADO}. Siempre responde en espa√±ol, de manera concisa y en lenguaje natural (prosa)."},
        ] + st.session_state.messages
        
        try:
            # Llamada a la API de Groq, usando el modelo SELECCIONADO
            stream = client.chat.completions.create(
                messages=messages_for_api,
                model=MODELO_SELECCIONADO, # <--- USAMOS LA VARIABLE DEL SELECTBOX
                stream=True
            )
            
            # Recopila el texto completo de la respuesta del asistente
            full_response = ""
            for chunk in stream:
                if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
                    full_response += chunk.choices[0].delta.content
                    # Actualizamos el contenido del placeholder con el cursor
                    message_placeholder.markdown(full_response + "‚ñå") 
            
            # Eliminamos el cursor final
            message_placeholder.markdown(full_response)
            
            # 3. Agrega la respuesta completa al historial de la sesi√≥n
            st.session_state.messages.append({"role": "assistant", "content": full_response})


        except Exception as e:
            error_message = f"Ocurri√≥ un error al contactar a la IA: {e}"
            st.error(error_message)
            st.session_state.messages.append({"role": "assistant", "content": error_message})

